{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c15a290b",
   "metadata": {},
   "source": [
    "Using pdfminer high-level api functions, extracts text from the Cambridge ebook of the MacLehose edition and saves into separate txt files per chapter, noting volume and section number [within the MacleHose edition], the geographical region [corresponding to the volume divisions of the 1599 edition], date, title [per CambridgeCore encoding] and page range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16d08c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apovzner\\Documents\\Hakluyt\\text-data\\CambridgeCore MacLehose PDFs\n"
     ]
    }
   ],
   "source": [
    "# set working directory\n",
    "import os\n",
    "os.chdir('text-data/CambridgeCore MacLehose PDFs')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718deb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf imports\n",
    "# pdfminer.high_level.extract_text(pdf_file, password='', page_numbers=None, maxpages=0, caching=True, codec='utf-8', laparams=None)\n",
    "# Parameters:\n",
    "    # pdf_file – Either a file path or a file-like object for the PDF file to be worked on.\n",
    "    # page_numbers – List of zero-indexed page numbers to extract.\n",
    "    # maxpages – The maximum number of pages to parse\n",
    "# Returns:\n",
    "# a string containing all of the text extracted.\n",
    "\n",
    "import pdfminer\n",
    "from pdfminer.high_level import extract_text\n",
    "from pdfminer.high_level import extract_pages\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe80dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_blank_lines(text):\n",
    "    '''\n",
    "    remove blank lines from text given as list of lines\n",
    "    parameters: text: chapter text split into lines\n",
    "    returns: all non-empty lines from text\n",
    "    '''\n",
    "    prev_len = len(text) + 1\n",
    "    while len(text) < prev_len:\n",
    "        prev_len = len(text)\n",
    "        try:\n",
    "            text.remove('')\n",
    "        except: pass\n",
    "    return(text)\n",
    "\n",
    "def find_date(headers):\n",
    "    '''\n",
    "    extract date from list of chapter headers\n",
    "    parameters: headers: list of lines from chapter headers\n",
    "    returns: date identified as the most common numberical component of the lines text zeroed to 4 digits\n",
    "    '''\n",
    "    headers_string = ''.join(headers)\n",
    "    numbers = re.findall(r'[0-9]+', headers_string)\n",
    "    if len(numbers) == 0: return 'XXXX'\n",
    "    elif len(numbers) == 1: common_number = numbers[0]\n",
    "    else:\n",
    "        common_number = max(set(numbers), key = numbers.count)\n",
    "    if int(common_number) > 300 and int(common_number) < 1620:\n",
    "        return common_number.zfill(4)\n",
    "    else:\n",
    "        return 'XXXX'\n",
    "\n",
    "def empty_page(lines):\n",
    "    '''\n",
    "    determine whether a page is empty of text content\n",
    "    parameters: lines: page text as lines\n",
    "    returns: True  if page contains less than 10 lines or lines average less than 3 chars\n",
    "    '''\n",
    "    #if len(lines_sans_blanks) < 10: return True  /// original mis-variable\n",
    "    if len(lines) < 10: return True\n",
    "    lines_lens = [len(line) for line in lines]\n",
    "    if sum(lines_lens)/len(lines_lens) < 4: return True    \n",
    "    return False\n",
    "\n",
    "def chapter_process(chapter):\n",
    "    '''\n",
    "    extract chapter text free of headers & footers and determine date\n",
    "    parameters: chapter: path of pdf chapter\n",
    "    returns: \n",
    "        chapter text as single string \n",
    "        date with leading zeroes to 4 digits or XXXX if failed to extract\n",
    "    possible enhancements:\n",
    "        resolve linebreak dashes\n",
    "        crop out side notes\n",
    "    '''\n",
    "    headers = []\n",
    "    chapter_text_list = []\n",
    "    chapter_pages = len(list(extract_pages(chapter)))\n",
    "\n",
    "    for pagenum in range(chapter_pages): \n",
    "        # process page by page, clearing headers, footers & blank lines; storing headers for date extract\n",
    "        text = extract_text(chapter, page_numbers = [pagenum])\n",
    "        lines = text.splitlines()\n",
    "        lines_sans_blanks = remove_blank_lines(lines)\n",
    "        if empty_page(lines_sans_blanks): continue\n",
    "        headers += lines_sans_blanks[:3]\n",
    "        if not ('.1_pp' in chapter and pagenum == 0):  #remove header except for first page of first chapter in each volume, which has no header\n",
    "            del lines_sans_blanks[:3]\n",
    "        del lines_sans_blanks[-4:] # remove footer\n",
    "        chapter_text_list += lines_sans_blanks\n",
    "\n",
    "    #override hyphen-broken words at ends of lines excepting the last\n",
    "    for i in range(len(chapter_text_list) - 1):\n",
    "        if chapter_text_list[i][-1] == '-':\n",
    "            chapter_text_list[i] = chapter_text_list[i][:-1] + chapter_text_list[i+1]\n",
    "            chapter_text_list[i+1] = ' '\n",
    "\n",
    "    #joining list of lines into one string and cleaning out extra spaces\n",
    "    chapter_text_string = ' '.join(chapter_text_list)\n",
    "    chapter_text_string = re.sub('\\s+',' ', chapter_text_string)\n",
    "    return(chapter_text_string, find_date(headers))\n",
    "\n",
    "def vol_chap_geog_prange(vol, chapter):\n",
    "    '''\n",
    "    extract volume, chapter number, broad geographical designation and title ready for feeding into txt file names\n",
    "    parameters: vol as int; chapter as path of pdf chapter\n",
    "    returns: \n",
    "            vol_z as number zeroed to 2 digits\n",
    "            chap_z as number zeroed to 2 digits\n",
    "            geog as CCCC determined by volume / chapter numbers below:\n",
    "                01.01-04.4: NNE-\n",
    "                04.05-06.17: SSE1\n",
    "                06.18-07.16: SSE2\n",
    "                07.17-11.43: AM-- \n",
    "            title as extracted from file name\n",
    "            page range zeroed to 3 digits each number\n",
    "    '''\n",
    "    chap = chapter[chapter.find('.') + 1 : chapter.find('_')] #extract chap num between first dot and first underscore\n",
    "    geog = 'XXXX' #to raise flag just in case something escapes\n",
    "    if vol in [1,2,3]:\n",
    "        geog = 'NNE-'\n",
    "    elif vol == 4:\n",
    "        if int(chap) in range(5): geog = 'NNE-'\n",
    "        else: geog = 'SSE1'\n",
    "    elif vol == 5:\n",
    "        geog = 'SSE1'\n",
    "    elif vol == 6:\n",
    "        if int(chap) in range(18): geog = 'SSE1'\n",
    "        else: geog = 'SSE2'\n",
    "    elif vol == 7:\n",
    "        if int(chap) in range(17): geog = 'SSE2'\n",
    "        else: geog = 'AMER'\n",
    "    else: geog = 'AMER'\n",
    "\n",
    "    title = chapter[:-4]\n",
    "    for i in range(4): # remove section & pages through 4th underscore\n",
    "        title = title[title.find('_') + 1:]\n",
    "\n",
    "    page_range = chapter\n",
    "    for i in range(2):\n",
    "        page_range = page_range[page_range.find('_') + 1:]\n",
    "    page_start = page_range[:page_range.find('_')]\n",
    "    page_range = page_range[page_range.find('_') + 1:]\n",
    "    page_end = page_range[:page_range.find('_')]\n",
    "    page_range = page_start.zfill(3) + '-' + page_end.zfill(3)\n",
    "    return(str(vol).zfill(2), chap.zfill(2), geog, title, page_range)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec5cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over volumes, then over chapter pdfs excluding front matter etc\n",
    "for vol in range(1,12):\n",
    "    filelist = os.scandir(os.getcwd() + '/' + str(vol))\n",
    "    for entry in filelist:\n",
    "        if entry.is_file(): \n",
    "            if (((vol == 1 and entry.name.startswith('06')) \n",
    "                or (vol > 1 and entry.name.startswith('04'))) \n",
    "                and entry.name[3] != '0'):  #identify body chapters\n",
    "                    print(str(vol) + '_' + entry.name)\n",
    "                    chapter = str(vol) + '/' + entry.name\n",
    "                    \n",
    "                    #extract and save text, extract file name components and fit into file name\n",
    "                    chapter_text, date = chapter_process(chapter)\n",
    "                    vol_n, chap_n, geog, title, page_range = vol_chap_geog_prange(vol, chapter)\n",
    "                    filename = vol_n + '_' + chap_n + '_' + geog + '_' + date + '_' + title + '_pp.' + page_range\n",
    "\n",
    "                    #create text file\n",
    "                    with open(filename + '.txt', 'w') as f:\n",
    "                        f.write(chapter_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfe3746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single file creation for debugging\n",
    "pdf_to_test = '06.42_pp_327_327_A_mandate_of_King_Edward_the_first_concerning_outlandish_Merchants'\n",
    "chapter = str(1) + '/' + pdf_to_test +'.pdf'\n",
    "\n",
    "#extract and save text, extract file name components and fit into file name\n",
    "chapter_text, date = chapter_process(chapter)\n",
    "vol_n, chap_n, geog, title, page_range = vol_chap_geog_prange(vol, chapter)\n",
    "filename = vol_n + '_' + chap_n + '_' + geog + '_' + date + '_' + title + '_pp.' + page_range\n",
    "\n",
    "#create text file\n",
    "with open(filename + '.txt', 'w') as f:\n",
    "    f.write(chapter_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1834ad",
   "metadata": {},
   "source": [
    "# Here and onward is testing code; do ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61292ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# filename format: 01 01 GEOG date TITLE [pagerange]\n",
    "vol = 10\n",
    "chapter = str(vol)+'/04.15_pp_178_183_The_voyage_and_valiant_fight_of_The_Content.pdf'\n",
    "\n",
    "# import pypdf2\n",
    "# from pypdf2 import pdffilereader\n",
    "\n",
    "chapter = 'croppeddoc2.pdf'\n",
    "print(extract_text(chapter, page_numbers = [0]))\n",
    "\n",
    "\n",
    "# #extract and save text, extract file name components and fit into file name\n",
    "# chapter_text, date = chapter_process(chapter)\n",
    "# vol_n, chap_n, geog, title, page_range = vol_chap_geog_prange(vol, chapter)\n",
    "# filename = vol_n + '_' + chap_n + '_' + geog + '_' + date + '_' + title + '_pp.' + page_range\n",
    "\n",
    "# #create text file\n",
    "# with open(filename + '.txt', 'w') as f:\n",
    "#     f.writelines(chapter_text)\n",
    "\n",
    "# # print(chapter_text, date)\n",
    "# # print(extract_text(chapter, page_numbers = [0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab28e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams, LTTextBox, LTTextLine, LTFigure\n",
    "\n",
    "fp = open('text-data/archive/other editions and text sources/MacLehose/04.25_pp_114_147_Libellus.pdf', 'rb')\n",
    "parser = PDFParser(fp)\n",
    "doc = PDFDocument(parser)\n",
    "\n",
    "rsrcmgr = PDFResourceManager()\n",
    "laparams = LAParams(line_overlap=0.5, char_margin=2.0, line_margin=0.5, word_margin=0.5, boxes_flow=-1, detect_vertical=False, all_texts=False)\n",
    "#word_margin of 0.5 / 0.7 seems to glue together the words that otherwise separate into disparate characters. not sure how to integrate that into the higher-level API page-getting though\n",
    "device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "for page in PDFPage.create_pages(doc):\n",
    "    interpreter.process_page(page)\n",
    "    layout = device.get_result()\n",
    "    parse_layout(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df4ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "laparams = LAParams(line_overlap=0.5, char_margin=2.0, line_margin=0.5, word_margin=0.5, boxes_flow=-1, detect_vertical=False, all_texts=False)\n",
    "\n",
    "text = extract_text('text-data/archive/other editions and text sources/MacLehose/04.25_pp_114_147_Libellus.pdf')\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
